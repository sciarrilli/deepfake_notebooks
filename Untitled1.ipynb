{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.5.0.zip\" to /home/ec2-user/.cache/torch/hub/v0.5.0.zip\n",
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /home/ec2-user/.cache/torch/checkpoints/resnext50_32x4d-7cdf4587.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ac209d2a0c4a38911c9b9b0f802833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100441675.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.5.0', 'resnext50_32x4d', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.7870e-01, -8.7607e-01, -1.0458e+00, -1.7807e+00, -2.8490e+00,\n",
      "         4.5469e-01, -3.1439e-01,  2.4608e+00,  4.6373e+00, -6.8706e-01,\n",
      "        -2.5154e+00, -1.7253e+00, -1.7181e+00, -1.6819e+00, -2.9249e+00,\n",
      "        -1.8234e+00, -2.3229e+00, -5.1976e-01, -3.3186e-01, -2.9749e-02,\n",
      "        -7.6930e-01, -8.5423e-01, -4.5674e-01,  1.6078e+00, -1.9731e+00,\n",
      "        -1.6912e+00, -1.1963e+00,  7.3291e-01, -8.7231e-01,  3.2870e-01,\n",
      "        -6.9123e-01,  7.1454e-03,  4.4783e-01, -2.2790e+00, -4.8503e-01,\n",
      "        -2.4070e+00, -1.0197e+00, -2.8373e+00, -2.2223e+00, -1.7164e+00,\n",
      "        -1.1307e+00, -2.6178e+00, -3.4507e+00, -2.6316e+00, -1.2086e+00,\n",
      "        -2.5106e+00, -1.2817e+00, -1.3505e+00, -3.1848e+00, -1.0038e-02,\n",
      "        -6.0860e-01, -4.1771e-01,  7.5805e-01, -4.4260e-01, -8.0626e-01,\n",
      "        -1.8484e-01, -1.2000e+00, -6.7037e-01, -1.7177e+00, -5.9534e-01,\n",
      "         1.5128e+00, -1.5361e+00, -2.4033e+00, -2.5055e+00, -1.0484e+00,\n",
      "        -2.4363e+00,  4.8588e-01, -9.9675e-01, -9.4252e-01, -3.0240e+00,\n",
      "        -1.8783e+00, -6.1587e-01, -1.7315e+00, -2.2235e+00, -8.1489e-01,\n",
      "         4.8962e-01, -1.8064e+00, -9.4066e-01,  2.0528e+00,  2.2895e-01,\n",
      "        -7.7780e-01,  5.8741e-03,  3.8367e-01, -8.0299e-01, -1.2196e+00,\n",
      "        -1.0102e+00, -7.1764e-01,  3.1282e-01, -2.2901e+00,  1.8605e+00,\n",
      "        -1.5004e+00, -3.6966e+00, -4.6605e+00, -1.1514e+00, -3.1781e-01,\n",
      "        -4.2151e+00, -1.1389e+00, -1.1035e+00, -2.0294e+00,  1.5532e+00,\n",
      "         1.3745e+00, -2.6042e+00,  3.4189e-01, -1.6257e+00,  6.2036e+00,\n",
      "         1.0488e+00,  9.0115e-01, -2.6115e+00, -1.8789e+00, -3.3525e+00,\n",
      "         9.0479e-01, -1.9976e+00,  9.0449e-01, -1.4724e+00, -3.7557e-01,\n",
      "        -1.3222e+00, -2.7698e+00, -1.2290e+00,  2.5555e-01, -1.1655e-01,\n",
      "        -2.6313e+00,  1.1739e-01, -9.9504e-01, -6.2059e-01, -1.9372e-01,\n",
      "        -7.9548e-01, -2.6222e+00,  2.0108e+00, -1.5462e+00,  2.4327e-01,\n",
      "         8.2153e-02, -2.5285e+00,  2.0517e-01, -4.1867e+00, -9.8851e-01,\n",
      "        -8.3740e-01, -1.4253e+00, -2.0110e+00, -3.2081e+00, -2.3900e+00,\n",
      "        -1.9535e+00, -1.5288e+00, -2.1819e+00, -6.5620e-01,  2.2281e-01,\n",
      "        -5.2470e-01, -9.4904e-02, -2.3266e+00, -1.9598e+00, -5.8981e-01,\n",
      "        -1.9144e+00,  3.9045e+00,  5.4922e+00,  3.6907e+00,  5.7570e+00,\n",
      "         2.4376e+00,  2.5608e+00,  5.3410e+00,  1.2700e+00,  1.8321e-01,\n",
      "         3.4581e-01, -3.3352e-01,  5.5312e-01,  4.2454e-01,  4.3723e-01,\n",
      "        -1.1886e+00, -2.2275e-01, -2.4205e+00,  8.2797e-01,  3.1245e+00,\n",
      "         1.6934e+00, -6.4815e-01, -1.8983e+00,  3.8789e-01,  5.7693e+00,\n",
      "         6.1200e-01, -3.8978e-01,  5.1964e-01, -1.3963e+00,  2.4552e+00,\n",
      "         2.0517e+00, -2.5958e-01,  1.0376e+00, -2.3902e-01,  1.5646e+00,\n",
      "         2.2818e+00,  3.5984e+00,  7.3929e-01,  1.5010e+00, -6.0088e-01,\n",
      "         6.1373e-02, -1.0523e+00,  2.7796e+00,  2.2412e+00,  6.3025e-02,\n",
      "         7.3702e-01, -2.0155e+00,  4.6284e-02, -1.4253e+00,  2.2948e+00,\n",
      "         2.8977e+00, -3.4402e-01,  1.3294e+00,  6.1164e+00,  2.2505e+00,\n",
      "        -5.4591e-03, -4.7789e-01,  4.8679e+00,  3.2670e+00,  7.3682e-02,\n",
      "        -1.8320e+00,  3.5384e-01,  1.4702e+00,  8.7198e-01,  5.6588e-01,\n",
      "         1.4094e+00,  3.2753e+00,  1.3732e+00,  7.5238e-01,  7.7934e-01,\n",
      "         1.1201e+00, -4.3340e-01,  8.6268e+00,  7.4867e+00,  7.7264e+00,\n",
      "         8.0646e-01,  3.6577e+00,  2.4718e+00,  4.2864e+00,  3.0647e+00,\n",
      "         6.6139e+00,  6.5276e+00,  5.9147e+00,  2.5096e+00,  1.0076e+00,\n",
      "         4.8477e+00,  1.0816e+00,  1.4623e+00,  6.9214e-01,  1.6765e+00,\n",
      "         2.0861e+00,  2.3101e+00,  1.7909e+00,  2.8628e-01,  4.1883e+00,\n",
      "         6.2070e-01, -6.7078e-02,  4.5630e+00,  9.8647e+00,  9.3403e+00,\n",
      "         7.5873e+00,  1.6589e+00,  1.2441e-01,  2.9986e+00,  7.8237e-01,\n",
      "         4.0804e+00,  5.8501e+00,  1.0518e+01,  1.8497e+01,  1.1726e+01,\n",
      "         1.0832e+01,  1.1499e+01,  3.7218e-01,  4.1874e+00,  2.2635e+00,\n",
      "         3.1024e+00,  2.5767e+00,  3.9878e+00, -1.1612e+00,  6.4143e+00,\n",
      "         1.1411e+01,  1.2128e+00,  2.7757e+00,  4.6537e+00,  4.9621e+00,\n",
      "        -8.3277e-01,  1.7934e+00,  2.6404e+00,  2.7684e+00,  9.6523e+00,\n",
      "         3.1256e+00,  2.5030e+00,  2.3126e+00,  7.1289e+00,  2.1251e+00,\n",
      "         1.0292e+00,  1.1246e-01,  3.0484e+00, -1.4328e-01,  1.6332e+00,\n",
      "        -1.3551e-01,  1.7615e+00,  1.8126e+00,  1.1623e+00,  6.7290e-01,\n",
      "         5.3422e-01,  2.8541e+00, -1.7554e+00, -1.6704e+00, -1.2595e+00,\n",
      "        -2.5743e+00, -1.1088e+00, -1.3074e+00, -1.9324e+00, -1.4544e+00,\n",
      "        -8.6934e-01, -9.7372e-01, -9.3300e-01, -1.9792e+00, -1.0228e+00,\n",
      "         2.0947e-01, -2.9561e+00, -2.0712e+00, -9.3478e-01,  1.3926e-01,\n",
      "        -3.3279e+00, -1.9325e+00, -2.5813e-01, -9.8721e-01, -3.2239e+00,\n",
      "        -1.3238e+00, -1.8597e+00, -3.4251e+00, -1.2041e+00, -1.1595e+00,\n",
      "        -1.9423e+00, -1.1825e+00,  1.3085e-01, -1.8810e+00, -4.0058e-03,\n",
      "         2.4469e+00,  3.8702e+00,  6.3738e+00,  2.6341e+00,  5.2460e-01,\n",
      "         5.0641e-01,  5.2558e-01, -8.3072e-02,  1.5550e+00,  9.7878e-01,\n",
      "        -4.7022e-01,  2.4512e+00, -2.2803e-01, -1.5578e+00, -2.0328e+00,\n",
      "         1.1688e+00, -5.2004e-01,  1.0404e+00,  2.8718e+00, -1.1125e+00,\n",
      "        -1.3291e+00, -3.4019e+00, -2.4685e+00, -3.8038e-01, -5.6574e-01,\n",
      "         4.0787e+00,  2.1465e+00,  1.1510e+00,  3.4424e+00,  2.7269e+00,\n",
      "        -1.7685e+00,  2.7183e+00, -1.1591e+00, -9.4628e-01, -2.6148e+00,\n",
      "        -2.0328e+00, -1.2511e+00, -1.2111e+00,  1.7815e+00, -8.7622e-01,\n",
      "        -8.0719e-01,  1.4175e-02,  1.3183e-01,  2.3180e+00,  8.4004e-01,\n",
      "        -2.7500e-01, -3.5731e+00,  2.7477e+00, -5.1409e-01,  8.9508e-01,\n",
      "         6.7744e-01, -1.2624e+00,  4.2151e-01,  4.5921e-01,  2.7139e-01,\n",
      "        -3.7932e+00, -4.2954e+00,  2.3152e+00,  3.6940e-01, -1.0565e+00,\n",
      "        -3.5696e+00, -3.9248e-01, -3.6616e+00, -2.8017e+00, -1.5257e+00,\n",
      "        -2.9039e+00, -2.6875e+00, -2.0685e+00, -2.1518e-01, -1.6554e+00,\n",
      "        -2.4274e+00, -7.6663e-01, -1.0721e+00, -2.1084e+00, -2.3225e+00,\n",
      "         6.8661e-01, -2.7136e+00, -1.2595e+00, -5.5687e-01,  5.6134e-01,\n",
      "        -1.3815e+00, -1.5945e+00,  6.9732e-01, -1.0410e-01, -9.0275e-01,\n",
      "        -5.3434e-01, -2.0361e+00,  4.4308e-01,  5.3158e-01,  9.1231e-01,\n",
      "         7.8725e-01,  2.9171e+00, -1.2346e+00, -1.8760e+00, -2.6344e-01,\n",
      "         8.1364e-01,  1.6410e+00,  1.1491e+00,  1.0973e+00,  2.5312e+00,\n",
      "        -2.0399e+00,  7.2692e-01,  1.7879e-01, -1.1949e+00, -2.3514e+00,\n",
      "         2.5312e+00,  8.4250e-02,  2.0309e+00, -2.5232e+00,  8.1408e-02,\n",
      "         1.8685e-01,  9.7159e-01, -5.7673e-01, -1.6131e+00,  2.8541e-01,\n",
      "         3.8018e-01, -2.8248e+00, -1.5145e-01, -1.0521e+00,  1.5312e-01,\n",
      "         1.3994e+00, -1.1876e+00,  1.1059e+00,  1.9755e-01, -7.1098e-01,\n",
      "        -8.5776e-02, -8.0873e-01,  9.7009e-01, -1.3019e-01, -9.1492e-01,\n",
      "         6.6905e-01, -2.1270e-01,  1.6827e+00,  2.6390e+00, -1.9140e+00,\n",
      "        -3.4688e-01, -1.6236e+00, -2.9016e+00, -1.5906e+00,  2.7439e+00,\n",
      "         1.8778e-01,  2.3101e+00,  4.6281e-01,  5.8948e-01, -2.2424e+00,\n",
      "        -1.3021e+00, -7.4001e-01,  2.1033e-01,  8.7195e-01,  2.0364e+00,\n",
      "         9.7718e-01, -1.4673e+00, -4.9971e-01,  5.5878e-01, -3.7626e-01,\n",
      "        -4.8785e-01, -1.0175e-01,  4.5354e-01,  2.7220e+00,  2.6920e+00,\n",
      "        -1.1306e+00, -1.4712e-01, -5.0890e-01,  2.4416e-02,  1.5948e-01,\n",
      "        -6.8843e-01, -7.7916e-01, -3.4159e-01, -2.5855e+00,  7.6498e-01,\n",
      "        -2.0930e+00,  1.4886e+00,  4.5992e-01, -3.1663e-01,  3.9504e-01,\n",
      "         7.7885e-01,  2.3926e+00,  1.5722e+00,  1.2344e+00, -1.8173e+00,\n",
      "        -1.9574e+00,  7.7899e-01, -3.4954e-01, -2.8198e-01, -1.7696e+00,\n",
      "         2.3963e+00,  4.1503e-01, -2.5532e+00, -2.4799e-01, -3.0827e-01,\n",
      "        -1.1095e+00,  1.7321e+00,  8.0086e-01,  3.1229e-01, -1.6737e+00,\n",
      "        -7.0104e-01,  2.9270e-01, -5.0199e-01,  3.3274e-01, -1.4499e+00,\n",
      "        -2.7538e-01,  1.4882e-01, -5.9528e-01, -1.4487e+00,  1.0680e+00,\n",
      "         1.0087e+00, -1.4185e+00,  3.6478e+00, -1.0116e+00,  3.1526e+00,\n",
      "        -2.7802e+00, -4.3120e-01,  1.3009e-01, -1.1180e+00,  3.3843e+00,\n",
      "         3.7023e-02, -9.7525e-01, -4.3436e+00, -5.7719e-01, -3.0645e+00,\n",
      "        -1.3524e+00, -1.2018e+00,  4.1397e-02, -5.8794e-01, -1.0598e-01,\n",
      "        -1.9632e+00,  1.3581e+00,  1.4767e+00, -2.1317e-01,  9.1150e-01,\n",
      "         1.1277e+00, -2.0313e+00, -1.9002e+00, -4.9874e-01, -1.5191e+00,\n",
      "        -4.1545e+00,  8.6963e-01, -1.7399e+00,  5.7770e-01, -1.3290e+00,\n",
      "         1.4831e+00, -2.1300e+00,  8.6792e-01, -1.1136e+00,  1.3751e+00,\n",
      "        -4.0503e-01, -8.7641e-01,  1.3218e-01,  9.2784e-01,  4.0879e-01,\n",
      "         1.9458e+00, -1.1912e+00, -1.0439e+00, -1.0973e-01, -1.5731e+00,\n",
      "         6.5544e-01, -7.4608e-01,  8.6667e-01, -1.5920e+00,  1.4302e+00,\n",
      "        -8.2613e-01, -1.9506e+00, -2.7691e+00,  4.7986e-01,  1.6556e-01,\n",
      "        -1.5252e+00,  2.0026e+00,  1.1788e+00, -1.0887e+00, -1.5911e+00,\n",
      "        -6.0369e-01,  3.5246e-01, -3.5874e-01, -5.2440e-01, -3.2529e-01,\n",
      "        -2.6571e+00,  1.4346e+00,  6.0787e-01, -2.8765e-01, -8.6384e-01,\n",
      "        -2.3660e+00, -6.9002e-01, -2.4441e+00,  4.0569e-01, -9.9141e-02,\n",
      "         1.7742e+00,  4.1438e-01, -3.2149e-01,  1.1537e+00, -1.6075e+00,\n",
      "        -9.8057e-01,  2.9494e+00,  1.5968e+00,  4.8398e-01, -2.3691e+00,\n",
      "         9.5257e-01, -9.3040e-02,  2.5816e-01,  6.5377e-01,  1.6895e+00,\n",
      "         2.3291e+00,  1.0559e+00,  5.1709e-01, -6.0477e-01, -2.4683e+00,\n",
      "         3.2470e-01, -2.7889e-01,  1.0586e+00, -7.0593e-01, -1.5274e+00,\n",
      "        -3.8317e-01,  1.3139e+00, -4.3491e-01,  8.8223e-02, -8.2829e-01,\n",
      "         3.4507e-01,  1.2090e+00, -8.2831e-01, -1.1874e+00, -9.9653e-01,\n",
      "        -9.6864e-01, -8.2033e-01,  1.3962e+00,  2.3534e+00, -8.6629e-01,\n",
      "        -5.1717e-02,  1.1383e+00,  1.6525e+00,  5.7312e-01, -1.3257e+00,\n",
      "        -3.5292e-01,  7.4355e-01, -2.6071e-01, -3.7328e+00, -5.8787e-02,\n",
      "        -7.3403e-01,  7.0901e-01,  1.0205e+00, -2.2119e+00, -1.3712e-01,\n",
      "        -7.6707e-01,  2.2790e-01,  1.0955e-01,  4.2608e-01, -1.4242e-01,\n",
      "        -7.3460e-01,  2.4601e+00, -1.3872e+00, -6.1034e-01, -5.5608e-01,\n",
      "         1.4658e+00, -5.8900e-01, -2.7685e+00, -1.4242e+00, -8.2422e-01,\n",
      "         2.3880e-01,  4.0669e-01, -3.0022e-01, -9.2986e-02, -1.4221e-01,\n",
      "        -1.4422e+00, -5.5784e-02, -9.5660e-01, -2.2237e+00, -8.8098e-01,\n",
      "        -5.2456e-01, -1.3753e+00, -8.0019e-01, -1.7394e+00, -1.0006e+00,\n",
      "         2.0933e+00, -1.2707e+00, -1.8244e+00,  5.3361e-01, -4.5595e-01,\n",
      "        -3.1618e+00,  1.0945e+00,  2.7640e-01,  8.6851e-01, -1.8917e+00,\n",
      "        -1.1418e-01, -1.4570e+00,  6.1502e-01, -1.1082e+00, -2.9870e-02,\n",
      "        -2.4903e+00,  5.8656e-01, -1.1168e+00,  6.0736e-02,  1.6647e+00,\n",
      "        -8.0764e-01, -1.1418e+00,  2.8697e+00,  4.1394e-01, -2.0404e+00,\n",
      "        -1.1612e+00, -2.9304e+00, -9.2365e-02,  1.9218e+00, -1.4595e+00,\n",
      "        -7.2398e-01,  2.8110e+00, -2.9816e+00,  6.7788e-02, -2.2645e+00,\n",
      "        -1.2604e+00, -2.0932e+00, -2.3047e-01, -2.8548e-01, -2.3790e+00,\n",
      "        -8.0441e-01, -1.6079e+00,  1.9528e+00, -5.9054e-01,  1.2145e+00,\n",
      "        -2.6634e+00, -8.6059e-01,  1.6631e+00, -8.9880e-01, -3.2266e+00,\n",
      "         1.1298e-01,  7.2593e-01,  1.6542e+00,  1.5840e+00, -3.0214e-01,\n",
      "        -3.8162e-01,  3.1350e+00,  9.3636e-01,  3.7151e-01, -1.6316e+00,\n",
      "        -9.6236e-01,  1.5622e+00, -1.7818e+00,  1.8022e+00,  3.9845e-01,\n",
      "         3.7208e-01,  1.3331e+00, -1.2984e+00,  1.7604e+00,  6.3812e-01,\n",
      "        -6.7742e-01, -9.5629e-02, -4.6722e-01, -1.1076e+00, -1.4311e+00,\n",
      "        -1.1597e+00,  3.4804e-01,  5.8655e-01, -8.9908e-01, -1.5087e+00,\n",
      "        -1.2695e+00,  1.1662e+00,  7.2859e-01,  1.1751e-01,  6.2322e-01,\n",
      "         1.2579e-01, -7.3171e-02,  1.5684e+00, -9.8156e-01,  4.5346e-01,\n",
      "        -1.8472e+00, -2.4307e-01,  3.3422e+00,  3.0406e-02, -1.5013e+00,\n",
      "        -8.4420e-01, -3.8117e-01,  2.0864e-01,  8.0038e-01,  6.0334e-01,\n",
      "        -1.9353e+00, -5.1818e-01, -1.2065e+00, -1.1783e+00, -1.1750e+00,\n",
      "         2.1393e+00, -3.3586e-01,  1.9362e+00, -1.9033e+00, -7.5728e-01,\n",
      "        -5.9035e-01,  1.9174e+00, -1.9983e+00,  8.6044e-01,  1.5549e-01,\n",
      "         1.4075e+00,  7.0487e-03, -1.1508e+00,  9.2278e-01, -1.0416e+00,\n",
      "        -2.3495e-01, -2.4844e+00, -4.3639e-01,  1.1774e+00,  4.3065e-01,\n",
      "        -2.9449e-01,  3.7372e+00,  4.1332e-01,  2.5666e+00, -2.7624e+00,\n",
      "         6.7233e-02,  9.5871e-01, -2.3633e+00,  6.0132e-01, -1.9572e-01,\n",
      "        -1.5412e+00, -1.7805e-03, -6.4592e-02,  1.9137e+00, -2.3090e+00,\n",
      "         5.7336e-01, -1.6918e+00, -1.5222e+00, -4.7969e-01, -4.8800e-01,\n",
      "         7.6683e-01, -7.3430e-01, -6.4451e-01, -4.1294e-02,  2.4712e-01,\n",
      "         4.5034e-01,  1.0396e+00,  4.2083e+00, -1.1749e+00, -2.5531e+00,\n",
      "        -1.8190e+00, -1.8795e+00, -2.0234e+00, -2.7690e-01, -1.2816e+00,\n",
      "        -9.4673e-01,  2.9278e-01, -2.0954e-01, -2.6408e+00, -2.0803e+00,\n",
      "        -1.0065e+00, -4.8866e-01,  2.2753e-01, -2.6108e+00,  2.0474e-01,\n",
      "         1.2492e+00, -9.2747e-01,  1.0637e+00, -1.7528e+00, -2.8017e+00,\n",
      "        -4.5718e-01,  2.2835e+00, -2.4804e+00, -5.1986e-01,  1.0829e+00,\n",
      "         1.3481e+00,  2.4540e-01,  2.6268e+00, -1.4605e+00, -7.6117e-01,\n",
      "        -2.0196e+00, -1.3293e+00, -4.1455e+00, -2.2354e+00, -2.3826e-01,\n",
      "        -2.0189e+00, -7.4972e-01,  7.5661e-01, -2.3832e+00, -1.2379e+00,\n",
      "        -2.0251e+00, -5.3161e-01,  1.4826e+00,  2.4471e+00,  9.5288e-01,\n",
      "         5.7266e-01, -5.0700e-01,  3.5361e+00, -1.0027e+00,  1.1244e+00,\n",
      "         8.2767e-01, -1.9912e+00, -4.3743e-01, -1.5812e+00, -3.2959e-01,\n",
      "         5.6617e-01, -1.6903e+00,  1.8512e+00, -1.2484e+00, -1.0188e+00,\n",
      "         1.1139e+00, -2.1472e-01, -2.4353e+00,  3.6877e-01, -2.1970e+00,\n",
      "        -1.5224e+00, -1.5131e+00, -2.6850e+00, -6.3413e-01, -5.9900e-01,\n",
      "        -1.3139e+00, -1.7107e+00, -1.1880e+00, -2.4206e+00,  2.2566e+00,\n",
      "        -7.8076e-01, -1.0393e-01,  2.0867e+00, -3.8725e+00, -1.1212e-01,\n",
      "        -2.7123e-02, -2.7455e-01,  1.9682e+00,  6.1356e-01, -3.8920e-01,\n",
      "        -2.3549e-01, -5.6331e-01, -1.2234e-01,  6.8520e-01, -1.0717e+00,\n",
      "         6.1109e-01, -1.2633e+00, -2.4330e+00,  1.2199e+00,  3.5916e-01,\n",
      "        -5.0088e-01, -2.8608e-01,  2.0594e-01, -1.5189e+00, -1.4516e+00,\n",
      "        -1.4324e+00,  1.8296e-02,  7.8025e-01, -1.5591e+00, -9.6258e-01,\n",
      "        -2.5162e+00,  6.5973e-01, -7.5464e-01, -6.5102e-01, -2.1044e+00,\n",
      "        -7.3796e-01, -7.7509e-01, -3.5216e-01,  2.0856e+00,  7.7610e-01,\n",
      "         1.4748e+00,  3.2462e+00, -9.1843e-01, -3.7382e+00,  6.0498e-03,\n",
      "         1.3129e+00, -1.1381e+00,  1.1539e+00, -1.5904e+00, -1.1344e+00,\n",
      "        -6.6500e-01,  1.4429e+00,  1.8425e+00, -1.9089e+00, -6.6017e-01,\n",
      "        -1.1404e-01, -1.1152e+00,  2.9149e-01,  9.9794e-01,  3.0459e-01,\n",
      "         2.2309e-01, -1.7534e+00, -9.4263e-01, -3.9674e+00, -2.6620e+00,\n",
      "        -1.0505e+00, -1.1299e+00, -2.2839e+00, -8.3326e-01,  1.1522e+00],\n",
      "       device='cuda:0')\n",
      "tensor([6.3170e-09, 3.8415e-09, 3.2420e-09, 1.5547e-09, 5.3415e-10, 1.4536e-08,\n",
      "        6.7366e-09, 1.0806e-07, 9.5264e-07, 4.6408e-09, 7.4566e-10, 1.6432e-09,\n",
      "        1.6550e-09, 1.7161e-09, 4.9510e-10, 1.4897e-09, 9.0396e-10, 5.4859e-09,\n",
      "        6.6199e-09, 8.9548e-09, 4.2744e-09, 3.9264e-09, 5.8428e-09, 4.6053e-08,\n",
      "        1.2825e-09, 1.7001e-09, 2.7890e-09, 1.9199e-08, 3.8560e-09, 1.2815e-08,\n",
      "        4.6215e-09, 9.2914e-09, 1.4437e-08, 9.4451e-10, 5.6798e-09, 8.3102e-10,\n",
      "        3.3276e-09, 5.4046e-10, 9.9968e-10, 1.6579e-09, 2.9780e-09, 6.7308e-10,\n",
      "        2.9265e-10, 6.6386e-10, 2.7547e-09, 7.4929e-10, 2.5607e-09, 2.3905e-09,\n",
      "        3.8180e-10, 9.1331e-09, 5.0196e-09, 6.0753e-09, 1.9688e-08, 5.9260e-09,\n",
      "        4.1193e-09, 7.6684e-09, 2.7786e-09, 4.7189e-09, 1.6557e-09, 5.0866e-09,\n",
      "        4.1879e-08, 1.9855e-09, 8.3413e-10, 7.5308e-10, 3.2334e-09, 8.0710e-10,\n",
      "        1.4997e-08, 3.4048e-09, 3.5946e-09, 4.4843e-10, 1.4100e-09, 4.9832e-09,\n",
      "        1.6330e-09, 9.9841e-10, 4.0839e-09, 1.5053e-08, 1.5151e-09, 3.6013e-09,\n",
      "        7.1858e-08, 1.1599e-08, 4.2382e-09, 9.2796e-09, 1.3540e-08, 4.1328e-09,\n",
      "        2.7246e-09, 3.3592e-09, 4.5010e-09, 1.2613e-08, 9.3412e-10, 5.9291e-08,\n",
      "        2.0577e-09, 2.2885e-10, 8.7285e-11, 2.9168e-09, 6.7136e-09, 1.3627e-10,\n",
      "        2.9536e-09, 3.0601e-09, 1.2124e-09, 4.3605e-08, 3.6470e-08, 6.8229e-10,\n",
      "        1.2985e-08, 1.8152e-09, 4.5620e-06, 2.6332e-08, 2.2717e-08, 6.7733e-10,\n",
      "        1.4092e-09, 3.2287e-10, 2.2799e-08, 1.2515e-09, 2.2793e-08, 2.1161e-09,\n",
      "        6.3368e-09, 2.4589e-09, 5.7817e-10, 2.6991e-09, 1.1911e-08, 8.2103e-09,\n",
      "        6.6405e-10, 1.0374e-08, 3.4106e-09, 4.9598e-09, 7.6006e-09, 4.1639e-09,\n",
      "        6.7017e-10, 6.8909e-08, 1.9655e-09, 1.1766e-08, 1.0015e-08, 7.3599e-10,\n",
      "        1.1326e-08, 1.4019e-10, 3.4330e-09, 3.9930e-09, 2.2182e-09, 1.2348e-09,\n",
      "        3.7299e-10, 8.4532e-10, 1.3079e-09, 2.0001e-09, 1.0408e-09, 4.7862e-09,\n",
      "        1.1528e-08, 5.4589e-09, 8.3900e-09, 9.0068e-10, 1.2997e-09, 5.1148e-09,\n",
      "        1.3601e-09, 4.5781e-07, 2.2398e-06, 3.6966e-07, 2.9189e-06, 1.0559e-07,\n",
      "        1.1943e-07, 1.9256e-06, 3.2849e-08, 1.1080e-08, 1.3036e-08, 6.6090e-09,\n",
      "        1.6040e-08, 1.4104e-08, 1.4284e-08, 2.8106e-09, 7.3831e-09, 8.1993e-10,\n",
      "        2.1114e-08, 2.0986e-07, 5.0168e-08, 4.8249e-09, 1.3821e-09, 1.3597e-08,\n",
      "        2.9550e-06, 1.7012e-08, 6.2474e-09, 1.5512e-08, 2.2834e-09, 1.0747e-07,\n",
      "        7.1780e-08, 7.1162e-09, 2.6038e-08, 7.2639e-09, 4.4104e-08, 9.0357e-08,\n",
      "        3.3710e-07, 1.9322e-08, 4.1387e-08, 5.0585e-09, 9.8092e-09, 3.2208e-09,\n",
      "        1.4865e-07, 8.6758e-08, 9.8254e-09, 1.9278e-08, 1.2293e-09, 9.6623e-09,\n",
      "        2.2181e-09, 9.1539e-08, 1.6727e-07, 6.5399e-09, 3.4860e-08, 4.1813e-06,\n",
      "        8.7567e-08, 9.1750e-09, 5.7205e-09, 1.1997e-06, 2.4200e-07, 9.9307e-09,\n",
      "        1.4769e-09, 1.3142e-08, 4.0131e-08, 2.2063e-08, 1.6246e-08, 3.7764e-08,\n",
      "        2.4403e-07, 3.6422e-08, 1.9576e-08, 2.0111e-08, 2.8276e-08, 5.9808e-09,\n",
      "        5.1469e-05, 1.6460e-05, 2.0917e-05, 2.0664e-08, 3.5767e-07, 1.0927e-07,\n",
      "        6.7068e-07, 1.9769e-07, 6.8761e-06, 6.3079e-06, 3.4175e-06, 1.1347e-07,\n",
      "        2.5269e-08, 1.1758e-06, 2.7209e-08, 3.9814e-08, 1.8432e-08, 4.9325e-08,\n",
      "        7.4294e-08, 9.2946e-08, 5.5303e-08, 1.2283e-08, 6.0805e-07, 1.7161e-08,\n",
      "        8.6267e-09, 8.8446e-07, 1.7749e-04, 1.0505e-04, 1.8200e-05, 4.8467e-08,\n",
      "        1.0447e-08, 1.8504e-07, 2.0172e-08, 5.4583e-07, 3.2038e-06, 3.4112e-04,\n",
      "        9.9568e-01, 1.1416e-03, 4.6697e-04, 9.1007e-04, 1.3385e-08, 6.0750e-07,\n",
      "        8.8712e-08, 2.0527e-07, 1.2134e-07, 4.9760e-07, 2.8884e-09, 5.6321e-06,\n",
      "        8.3336e-04, 3.1022e-08, 1.4806e-07, 9.6843e-07, 1.3182e-06, 4.0115e-09,\n",
      "        5.5440e-08, 1.2933e-07, 1.4698e-07, 1.4352e-04, 2.1009e-07, 1.1273e-07,\n",
      "        9.3182e-08, 1.1509e-05, 7.7249e-08, 2.5820e-08, 1.0323e-08, 1.9449e-07,\n",
      "        7.9938e-09, 4.7234e-08, 8.0562e-09, 5.3701e-08, 5.6519e-08, 2.9495e-08,\n",
      "        1.8081e-08, 1.5739e-08, 1.6014e-07, 1.5945e-09, 1.7359e-09, 2.6181e-09,\n",
      "        7.0300e-10, 3.0440e-09, 2.4955e-09, 1.3358e-09, 2.1544e-09, 3.8675e-09,\n",
      "        3.4841e-09, 3.6290e-09, 1.2747e-09, 3.3174e-09, 1.1375e-08, 4.7992e-10,\n",
      "        1.1627e-09, 3.6225e-09, 1.0604e-08, 3.3088e-10, 1.3357e-09, 7.1265e-09,\n",
      "        3.4375e-09, 3.6715e-10, 2.4550e-09, 1.4365e-09, 3.0024e-10, 2.7672e-09,\n",
      "        2.8934e-09, 1.3226e-09, 2.8277e-09, 1.0515e-08, 1.4062e-09, 9.1884e-09,\n",
      "        1.0657e-07, 4.4238e-07, 5.4088e-06, 1.2851e-07, 1.5589e-08, 1.5308e-08,\n",
      "        1.5604e-08, 8.4898e-09, 4.3682e-08, 2.4550e-08, 5.7646e-09, 1.0703e-07,\n",
      "        7.3442e-09, 1.9428e-09, 1.2082e-09, 2.9687e-08, 5.4844e-09, 2.6111e-08,\n",
      "        1.6300e-07, 3.0327e-09, 2.4421e-09, 3.0729e-10, 7.8151e-10, 6.3064e-09,\n",
      "        5.2394e-09, 5.4491e-07, 7.8920e-08, 2.9163e-08, 2.8840e-07, 1.4102e-07,\n",
      "        1.5738e-09, 1.3980e-07, 2.8946e-09, 3.5811e-09, 6.7515e-10, 1.2083e-09,\n",
      "        2.6402e-09, 2.7480e-09, 5.4787e-08, 3.8410e-09, 4.1155e-09, 9.3569e-09,\n",
      "        1.0525e-08, 9.3685e-08, 2.1370e-08, 7.0072e-09, 2.5894e-10, 1.4398e-07,\n",
      "        5.5171e-09, 2.2579e-08, 1.8163e-08, 2.6104e-09, 1.4062e-08, 1.4602e-08,\n",
      "        1.2102e-08, 2.0779e-10, 1.2575e-10, 9.3422e-08, 1.3348e-08, 3.2073e-09,\n",
      "        2.5986e-10, 6.2306e-09, 2.3702e-10, 5.6004e-10, 2.0062e-09, 5.0564e-10,\n",
      "        6.2777e-10, 1.1659e-09, 7.4392e-09, 1.7621e-09, 8.1431e-10, 4.2858e-09,\n",
      "        3.1576e-09, 1.1202e-09, 9.0435e-10, 1.8330e-08, 6.1162e-10, 2.6180e-09,\n",
      "        5.2861e-09, 1.6172e-08, 2.3174e-09, 1.8728e-09, 1.8528e-08, 8.3132e-09,\n",
      "        3.7404e-09, 5.4065e-09, 1.2043e-09, 1.4368e-08, 1.5698e-08, 2.2972e-08,\n",
      "        2.0271e-08, 1.7055e-07, 2.6842e-09, 1.4133e-09, 7.0887e-09, 2.0813e-08,\n",
      "        4.7607e-08, 2.9108e-08, 2.7639e-08, 1.1595e-07, 1.1997e-09, 1.9084e-08,\n",
      "        1.1031e-08, 2.7928e-09, 8.7853e-10, 1.1594e-07, 1.0036e-08, 7.0307e-08,\n",
      "        7.3987e-10, 1.0008e-08, 1.1121e-08, 2.4374e-08, 5.1821e-09, 1.8383e-09,\n",
      "        1.2272e-08, 1.3492e-08, 5.4723e-10, 7.9288e-09, 3.2215e-09, 1.0752e-08,\n",
      "        3.7388e-08, 2.8132e-09, 2.7878e-08, 1.1240e-08, 4.5311e-09, 8.4669e-09,\n",
      "        4.1092e-09, 2.4338e-08, 8.0991e-09, 3.6952e-09, 1.8011e-08, 7.4576e-09,\n",
      "        4.9631e-08, 1.2915e-07, 1.3606e-09, 6.5212e-09, 1.8190e-09, 5.0678e-10,\n",
      "        1.8802e-09, 1.4343e-07, 1.1131e-08, 9.2952e-08, 1.4655e-08, 1.6634e-08,\n",
      "        9.7978e-10, 2.5088e-09, 4.4014e-09, 1.1385e-08, 2.2063e-08, 7.0690e-08,\n",
      "        2.4511e-08, 2.1269e-09, 5.5970e-09, 1.6131e-08, 6.3324e-09, 5.6638e-09,\n",
      "        8.3328e-09, 1.4519e-08, 1.4032e-07, 1.3618e-07, 2.9782e-09, 7.9632e-09,\n",
      "        5.5458e-09, 9.4533e-09, 1.0820e-08, 4.6345e-09, 4.2324e-09, 6.5558e-09,\n",
      "        6.9519e-10, 1.9824e-08, 1.1376e-09, 4.0876e-08, 1.4612e-08, 6.7215e-09,\n",
      "        1.3694e-08, 2.0102e-08, 1.0095e-07, 4.4440e-08, 3.1700e-08, 1.4987e-09,\n",
      "        1.3028e-09, 2.0104e-08, 6.5039e-09, 6.9585e-09, 1.5719e-09, 1.0132e-07,\n",
      "        1.3971e-08, 7.1804e-10, 7.1991e-09, 6.7779e-09, 3.0418e-09, 5.2144e-08,\n",
      "        2.0549e-08, 1.2607e-08, 1.7303e-09, 4.5763e-09, 1.2362e-08, 5.5843e-09,\n",
      "        1.2867e-08, 2.1643e-09, 7.0046e-09, 1.0706e-08, 5.0869e-09, 2.1667e-09,\n",
      "        2.6841e-08, 2.5296e-08, 2.2332e-09, 3.5416e-07, 3.3545e-09, 2.1583e-07,\n",
      "        5.7219e-10, 5.9939e-09, 1.0507e-08, 3.0159e-09, 2.7211e-07, 9.5732e-09,\n",
      "        3.4788e-09, 1.1983e-10, 5.1797e-09, 4.3059e-10, 2.3859e-09, 2.7737e-09,\n",
      "        9.6152e-09, 5.1243e-09, 8.2976e-09, 1.2953e-09, 3.5875e-08, 4.0392e-08,\n",
      "        7.4542e-09, 2.2953e-08, 2.8493e-08, 1.2101e-09, 1.3796e-09, 5.6024e-09,\n",
      "        2.0195e-09, 1.4477e-10, 2.2012e-08, 1.6194e-09, 1.6439e-08, 2.4422e-09,\n",
      "        4.0652e-08, 1.0963e-09, 2.1974e-08, 3.0292e-09, 3.6491e-08, 6.1528e-09,\n",
      "        3.8402e-09, 1.0529e-08, 2.3331e-08, 1.3884e-08, 6.4573e-08, 2.8032e-09,\n",
      "        3.2479e-09, 8.2666e-09, 1.9133e-09, 1.7768e-08, 4.3748e-09, 2.1947e-08,\n",
      "        1.8774e-09, 3.8559e-08, 4.0383e-09, 1.3117e-09, 5.7861e-10, 1.4907e-08,\n",
      "        1.0886e-08, 2.0071e-09, 6.8346e-08, 2.9988e-08, 3.1057e-09, 1.8791e-09,\n",
      "        5.0442e-09, 1.3123e-08, 6.4443e-09, 5.4605e-09, 6.6635e-09, 6.4716e-10,\n",
      "        3.8728e-08, 1.6942e-08, 6.9191e-09, 3.8888e-09, 8.6582e-10, 4.6271e-09,\n",
      "        8.0076e-10, 1.3841e-08, 8.3545e-09, 5.4386e-08, 1.3962e-08, 6.6889e-09,\n",
      "        2.9244e-08, 1.8487e-09, 3.4604e-09, 1.7616e-07, 4.5549e-08, 1.4968e-08,\n",
      "        8.6312e-10, 2.3915e-08, 8.4056e-09, 1.1942e-08, 1.7738e-08, 4.9970e-08,\n",
      "        9.4727e-08, 2.6520e-08, 1.5472e-08, 5.0388e-09, 7.8163e-10, 1.2764e-08,\n",
      "        6.9801e-09, 2.6591e-08, 4.5540e-09, 2.0029e-09, 6.2888e-09, 3.4325e-08,\n",
      "        5.9717e-09, 1.0076e-08, 4.0296e-09, 1.3027e-08, 3.0906e-08, 4.0295e-09,\n",
      "        2.8139e-09, 3.4056e-09, 3.5019e-09, 4.0618e-09, 3.7270e-08, 9.7061e-08,\n",
      "        3.8793e-09, 8.7603e-09, 2.8797e-08, 4.8154e-08, 1.6364e-08, 2.4503e-09,\n",
      "        6.4820e-09, 1.9404e-08, 7.1081e-09, 2.2073e-10, 8.6986e-09, 4.4278e-09,\n",
      "        1.8746e-08, 2.5597e-08, 1.0101e-09, 8.0432e-09, 4.2839e-09, 1.1587e-08,\n",
      "        1.0293e-08, 1.4126e-08, 8.0007e-09, 4.4253e-09, 1.0799e-07, 2.3043e-09,\n",
      "        5.0108e-09, 5.2902e-09, 3.9955e-08, 5.1189e-09, 5.7893e-10, 2.2205e-09,\n",
      "        4.0460e-09, 1.1714e-08, 1.3855e-08, 6.8327e-09, 8.4061e-09, 8.0023e-09,\n",
      "        2.1809e-09, 8.7247e-09, 3.5443e-09, 9.9825e-10, 3.8227e-09, 5.4597e-09,\n",
      "        2.3318e-09, 4.1444e-09, 1.6202e-09, 3.3918e-09, 7.4832e-08, 2.5888e-09,\n",
      "        1.4882e-09, 1.5730e-08, 5.8474e-09, 3.9070e-10, 2.7563e-08, 1.2162e-08,\n",
      "        2.1987e-08, 1.3913e-09, 8.2298e-09, 2.1489e-09, 1.7064e-08, 3.0456e-09,\n",
      "        8.9538e-09, 7.6466e-10, 1.6585e-08, 3.0196e-09, 9.8029e-09, 4.8749e-08,\n",
      "        4.1136e-09, 2.9452e-09, 1.6265e-07, 1.3956e-08, 1.1990e-09, 2.8886e-09,\n",
      "        4.9242e-10, 8.4113e-09, 6.3035e-08, 2.1435e-09, 4.4726e-09, 1.5338e-07,\n",
      "        4.6783e-10, 9.8723e-09, 9.5830e-10, 2.6156e-09, 1.1374e-09, 7.3263e-09,\n",
      "        6.9342e-09, 8.5464e-10, 4.1269e-09, 1.8479e-09, 6.5023e-08, 5.1111e-09,\n",
      "        3.1076e-08, 6.4312e-10, 3.9015e-09, 4.8671e-08, 3.7552e-09, 3.6617e-10,\n",
      "        1.0329e-08, 1.9065e-08, 4.8236e-08, 4.4966e-08, 6.8196e-09, 6.2986e-09,\n",
      "        2.1207e-07, 2.3531e-08, 1.3376e-08, 1.8046e-09, 3.5240e-09, 4.4000e-08,\n",
      "        1.5529e-09, 5.5930e-08, 1.3741e-08, 1.3384e-08, 3.4988e-08, 2.5182e-09,\n",
      "        5.3645e-08, 1.7463e-08, 4.6857e-09, 8.3839e-09, 5.7818e-09, 3.0476e-09,\n",
      "        2.2054e-09, 2.8927e-09, 1.3066e-08, 1.6585e-08, 3.7542e-09, 2.0406e-09,\n",
      "        2.5922e-09, 2.9610e-08, 1.9116e-08, 1.0376e-08, 1.7204e-08, 1.0462e-08,\n",
      "        8.5743e-09, 4.4270e-08, 3.4569e-09, 1.4518e-08, 1.4546e-09, 7.2346e-09,\n",
      "        2.6089e-07, 9.5101e-09, 2.0558e-09, 3.9660e-09, 6.3014e-09, 1.1365e-08,\n",
      "        2.0539e-08, 1.6866e-08, 1.3320e-09, 5.4946e-09, 2.7606e-09, 2.8394e-09,\n",
      "        2.8488e-09, 7.8354e-08, 6.5935e-09, 6.3954e-08, 1.3753e-09, 4.3261e-09,\n",
      "        5.1120e-09, 6.2764e-08, 1.2506e-09, 2.1810e-08, 1.0777e-08, 3.7692e-08,\n",
      "        9.2905e-09, 2.9187e-09, 2.3213e-08, 3.2556e-09, 7.2936e-09, 7.6919e-10,\n",
      "        5.9629e-09, 2.9944e-08, 1.4191e-08, 6.8720e-09, 3.8727e-07, 1.3947e-08,\n",
      "        1.2013e-07, 5.8246e-10, 9.8668e-09, 2.4062e-08, 8.6816e-10, 1.6832e-08,\n",
      "        7.5854e-09, 1.9753e-09, 9.2088e-09, 8.6482e-09, 6.2532e-08, 9.1666e-10,\n",
      "        1.6368e-08, 1.6991e-09, 2.0133e-09, 5.7102e-09, 5.6629e-09, 1.9861e-08,\n",
      "        4.4267e-09, 4.8425e-09, 8.8521e-09, 1.1811e-08, 1.4473e-08, 2.6090e-08,\n",
      "        6.2033e-07, 2.8494e-09, 7.1810e-10, 1.4963e-09, 1.4084e-09, 1.2197e-09,\n",
      "        6.9939e-09, 2.5609e-09, 3.5795e-09, 1.2363e-08, 7.4813e-09, 6.5782e-10,\n",
      "        1.1522e-09, 3.3718e-09, 5.6592e-09, 1.1582e-08, 6.7780e-10, 1.1321e-08,\n",
      "        3.2172e-08, 3.6491e-09, 2.6726e-08, 1.5986e-09, 5.6003e-10, 5.8402e-09,\n",
      "        9.0506e-08, 7.7225e-10, 5.4854e-09, 2.7244e-08, 3.5520e-08, 1.1791e-08,\n",
      "        1.2758e-07, 2.1414e-09, 4.3093e-09, 1.2243e-09, 2.4415e-09, 1.4609e-10,\n",
      "        9.8667e-10, 7.2694e-09, 1.2252e-09, 4.3589e-09, 1.9659e-08, 8.5109e-10,\n",
      "        2.6752e-09, 1.2175e-09, 5.4213e-09, 4.0632e-08, 1.0660e-07, 2.3923e-08,\n",
      "        1.6356e-08, 5.5564e-09, 3.1672e-07, 3.3846e-09, 2.8400e-08, 2.1107e-08,\n",
      "        1.2596e-09, 5.9567e-09, 1.8980e-09, 6.6350e-09, 1.6250e-08, 1.7018e-09,\n",
      "        5.8742e-08, 2.6473e-09, 3.3306e-09, 2.8103e-08, 7.4426e-09, 8.0787e-10,\n",
      "        1.3339e-08, 1.0253e-09, 2.0128e-09, 2.0316e-09, 6.2938e-10, 4.8930e-09,\n",
      "        5.0680e-09, 2.4795e-09, 1.6673e-09, 2.8123e-09, 8.1985e-10, 8.8107e-08,\n",
      "        4.2257e-09, 8.3146e-09, 7.4338e-08, 1.9194e-10, 8.2468e-09, 8.9784e-09,\n",
      "        7.0104e-09, 6.6030e-08, 1.7039e-08, 6.2510e-09, 7.2896e-09, 5.2521e-09,\n",
      "        8.1630e-09, 1.8304e-08, 3.1588e-09, 1.6997e-08, 2.6083e-09, 8.0974e-10,\n",
      "        3.1245e-08, 1.3212e-08, 5.5904e-09, 6.9300e-09, 1.1335e-08, 2.0198e-09,\n",
      "        2.1605e-09, 2.2025e-09, 9.3956e-09, 2.0130e-08, 1.9403e-09, 3.5232e-09,\n",
      "        7.4510e-10, 1.7844e-08, 4.3375e-09, 4.8111e-09, 1.1248e-09, 4.4105e-09,\n",
      "        4.2497e-09, 6.4869e-09, 7.4254e-08, 2.0046e-08, 4.0316e-08, 2.3703e-07,\n",
      "        3.6822e-09, 2.1953e-10, 9.2812e-09, 3.4289e-08, 2.9559e-09, 2.9249e-08,\n",
      "        1.8806e-09, 2.9669e-09, 4.7443e-09, 3.9051e-08, 5.8231e-08, 1.3676e-09,\n",
      "        4.7672e-09, 8.2309e-09, 3.0244e-09, 1.2347e-08, 2.5025e-08, 1.2510e-08,\n",
      "        1.1531e-08, 1.5976e-09, 3.5942e-09, 1.7456e-10, 6.4399e-10, 3.2267e-09,\n",
      "        2.9803e-09, 9.3992e-10, 4.0096e-09, 2.9199e-08], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "print(torch.nn.functional.softmax(output[0], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
