{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake Detection Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download dataset by using chrome inspector. Click the 'all.zip' and cancel the download. Then in chrome inspector use copy as cURL to copy to SageMaker\n",
    "2. Figure out opencv to convert the mp4's to images\n",
    "3. Balance out the dataset since it has more fakes than reals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "video_path = '/home/ec2-user/.fastai/data/deepfake/dfdc_train_part_0/'\n",
    "\n",
    "labels = pd.read_json(open(os.path.join(video_path,'metadata.json')))\n",
    "labels = labels.transpose()\n",
    "labels['filename'] = labels.axes[0].tolist()\n",
    "cols = ['filename','label','split','original']\n",
    "labels = labels[cols]\n",
    "labels.index = list(range(labels.shape[0]))\n",
    "labels.to_csv('labels.csv')\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.mkdir('/home/ec2-user/.fastai/data/deepfake/dfdc_train_part_0/images')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list = labels['filename']\n",
    "video_path = '/home/ec2-user/.fastai/data/deepfake/dfdc_train_part_0/'\n",
    "\n",
    "def videoConverter(video):\n",
    "    vidcap = cv2.VideoCapture(os.path.join(video_path,video))\n",
    "    def getFrame(sec):\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "        hasFrames,image = vidcap.read()\n",
    "        if hasFrames:\n",
    "            image_path = '/home/ec2-user/.fastai/data/deepfake/dfdc_train_part_0/images'\n",
    "            cv2.imwrite(os.path.join(image_path, video + '_' + str(count) + \".jpg\"), image)\n",
    "        return hasFrames\n",
    "    sec = 0\n",
    "    frameRate = 0.5 #//it will capture image in each 0.5 second\n",
    "    count=1\n",
    "    success = getFrame(sec)\n",
    "    while success:\n",
    "        count = count + 1\n",
    "        sec = sec + frameRate\n",
    "        sec = round(sec, 2)\n",
    "        success = getFrame(sec)\n",
    "\n",
    "        \n",
    "for video in video_list:\n",
    "    videoConverter(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
